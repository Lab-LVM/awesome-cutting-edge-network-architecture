# Awesome Cutting-Edge Network Architecture

This repository contains the paper lists of recent computer vision architecture
---

## Overview

- [introduction](#introduction)
- [Base of Vision Transformer](#Base-of-Vision-Transformer)
- [Representative Local Attention](#Representative-Local-Attention)

## Introduction

The paper lists of recent computer vision architecture.
we deal with the cutting-edge network of computer vision, starting with the contents of ViT and the difference between CNN and ViT.



## Base of Vision Transformer

- **ViT**: "An Image is Worth 16x16 Words: Transformers for Image Recognetion at Scale", ICLR, 2021 [[paper](https://arxiv.org/abs/2010.11929)] [[code](https://github.com/rwightman/pytorch-image-models/blob/main/timm/models/vision_transformer.py)] [[summary](summary/Vit.md)]

- **ViT vs CNN**: "Do Vision Transformers See Like Convolutional Neural Networks?", NeurIPS, 2021 [[paper](https://arxiv.org/abs/2108.08810)] [[code](https://github.com/AntixK/PyTorch-Model-Compare)] [[summary](summary/ViTvsCNN.md)]

- **How to train ViT**: "How to train your ViT? Data, Augmentation,and Regularization in Vision Transformers", Arxiv 2021 [[paper](https://arxiv.org/abs/2106.10270)] [[code](https://github.com/rwightman/pytorch-image-models/blob/main/timm/models/vision_transformer.py)] [[summary](summary/How_to_train_ViT.md)]

## Representative Local Attention
- **Swin Transformer**: "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows", ICCV, 2021 [[paper](https://arxiv.org/abs/2103.14030)] [[code](https://github.com/rwightman/pytorch-image-models/blob/main/timm/models/swin_transformer.py)] [[summary](summary/SwinTransformer.md)]

- **Swin Transformer V2**: "Swin Transformer V2: Scaling Up Capacity and Resolution", CVPR, 2022 [[paper](https://arxiv.org/abs/2111.09883)] [[code](https://github.com/rwightman/pytorch-image-models/blob/main/timm/models/swin_transformer_v2.py)] [[summary](summary/SwinTransformerV2.md)]

- **VOLO**: "VOLO: Vision Outlooker for Visual Recognition", TPAMI(early access), 2022 [[paper](https://arxiv.org/abs/2106.13112)] [[code](https://github.com/rwightman/pytorch-image-models/blob/main/timm/models/volo.py)] [[summary](summary/VOLO.md)]

- 
